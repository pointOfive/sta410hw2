{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3aa0add",
   "metadata": {},
   "source": [
    "# STA410 Programming Portfolio Assignment 2 (25 points)\n",
    "\n",
    "Welcome.\n",
    "\n",
    "## Rules\n",
    "\n",
    "0. Point awards for assigning the correct values into variables are indicated along with each required variable assignment name.\n",
    "\n",
    "1. **Do not delete or replace cells**: this erases cell ids upon which automated scoring is based.\n",
    "    - Cell ids are supported by [notebook format 4.5](https://github.com/jupyterlab/jupyterlab/issues/9729) or greater, and [jupyterlab](https://jupyter.org/install) version\n",
    "[3.0.13 or greater](https://github.com/jupyterlab/jupyterlab/releases/tag/v3.0.13). If the environment you work in does not support cell ids you will not get any credit for your submitted homework.  [UofT JupyterHub](https://jupyter.utoronto.ca) and [Google Colab](https://colab.research.google.com) support cell ids.\n",
    "      > You may check if cell ids are present or changing at each save with `! grep '\"id\":' <path/to/notebook>.ipynb`\n",
    "\n",
    "    - *You may add cells for scratch work*, but if required answers are not submitted through the provided cells where the answers are requested your answers will not be graded.\n",
    "    - *If you accidentally delete a required cell*, try \"Edit > Undo Delete Cells\" in the notebook editor; otherwise, redownload the notebook (so it has the correct required cells ids) and repopulate it with your answers (assuming you don't overwrite them).\n",
    "    \n",
    "    \n",
    "2. **No cells may have any runtime errors**: this causes subsequent tests to fail and you will not get credit for tests which fail because of previous runtime errors.\n",
    "    - The `try`-`except` block syntax \"catches\" runtime errors and transforms them into `exceptions` which are no longer runtime errors.  These `exceptions` will not cause subsequent tests to fail.\n",
    "    \n",
    "\n",
    "3. **No jupyter shortcut commands, e.g.,** `! python script.py 10` or `%%timeit` **may be included in the final submission**: they will cause subsequent tests to fail.\n",
    "\n",
    "    - Comment out jupyter shortcut commands, e.g., `# ! python script.py 10` or `# %%timeit` in submitted notebooks.\n",
    "    \n",
    "\n",
    "4. Specific code solutions submitted for these assignments must be created either individually or in the context of a paired effort.\n",
    "  \n",
    "  - Students may work individually.  \n",
    "    - Students choosing to work individually must work in accordance with the [University Student Academic Integrity values](https://www.artsci.utoronto.ca/current/academic-advising-and-support/student-academic-integrity)  of \"honesty, trust, fairness, respect, responsibility and courage.\"\n",
    "  - Students may self-select pairs for each assignment.\n",
    "    - Paired students work together and may share work without restriction within their pair; but, must otherwise work in accordance with the [University Student Academic Integrity values](https://www.artsci.utoronto.ca/current/academic-advising-and-support/student-academic-integrity) noted above.\n",
    "    - Paired students each separately submit their (common) work, including (agreeing) contribution of work statements for each problem.\n",
    "    \n",
    "    *Please seek homework partners in person or on the course discussion board on Quercus. Groups of three or more are not allowed; however, students are welcome to amicably seek new partners for each new assignment.* \n",
    "\n",
    "  ***Getting and sharing \"hints\" from other classmates is allowed; but, the eventual code creation work and submission must be your own individual or paired creation.***\n",
    "\n",
    "\n",
    "5. The homework is open book, open notes, open internet, etc.\n",
    "\n",
    "6. You may use any functions available from all library imports below; otherwise, you are expected to create your own Python functionality based on the Python stdlib (standard libary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e256d28",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# You may use any functions available from the following library imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.fft import fft, ifft\n",
    "from numpy.fft import fft, ifft\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d48de6e",
   "metadata": {},
   "source": [
    "# Problem 0 (required)\n",
    "\n",
    "Are you working with a partner to complete this assignment?  \n",
    "- If not, assign  the value of `None` into the variable `Partner`.\n",
    "- If so, assign the name of the person you worked with into the variable `Partner`.\n",
    "    - Format the name as `\"<First Name> <Last Name>\"` as a `str` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf78081a",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Required\n",
    "Partner = #None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d482b3e6",
   "metadata": {},
   "source": [
    "What was your contribution in completing the code for this assignments problems? Assign one of the following into each of the `Problem_X` variables below.\n",
    "\n",
    "- `\"I worked alone\"`\n",
    "- `\"I contributed more than my partner\"`\n",
    "- `\"My partner and I contributed equally\"`\n",
    "- `\"I contributed less than my partner\"`\n",
    "- `\"I did not contribute\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6589b6a8",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Required\n",
    "Problem_1 = #\"I worked alone\"\n",
    "Problem_2 = #\"I worked alone\"\n",
    "Problem_3 = #\"I worked alone\"\n",
    "Problem_4 = #\"I worked alone\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08adf26b",
   "metadata": {},
   "source": [
    "# Problem 1 (5 points)\n",
    "\n",
    "Write a function `construct_Lagrange_piecewise_polynomial(x, y, order)` which returns a function which\n",
    "***interpolates*** $(x,y)$ with an ***order-k Lagrange piecewise polynomial***, i.e., the piecewise continuous concatentation of $m$ ***Lagrange polynomials*** \n",
    "\n",
    "\\begin{align*}\n",
    "l_{gj}(w) = {} & \\underset{ i \\not = gk+j}{\\prod_{i = gk}^{(g+1)k}} \\frac{w-x_{(i)}}{x_{(gk+j)}-x_{(i)}}  \\underset{ 1_A(a)=1 \\text{ if } a\\in A; 0 \\text{ otherwise}}{\\times\\; 1_{\\left[x_{\\left(gk^\\vphantom{1pt}\\right)}, x_{\\left((gk+k^\\vphantom{1pt}\\right) } \\right)}(w)} && x_{(i)} < x_{(j)} \\text{ for } i<j\\\\\n",
    "   h(w) = {} & \\sum_g \\sum_{j} y_{(j)} l_{gj}(w) + \\underset{\\text{so } h(x_{(n)}) = y_{(n)}}{y_{(n)} \\delta_{x_{(n)}}(w)} && y_{(j)} \\text{ corresponds to } x_{(j)}\n",
    "\\end{align*}\n",
    "\n",
    "where for $g = 0, 1, \\cdots, m$ and $j=0,1,\\cdots, k$ each $l_{gj}(w)$ is the $j^{th}$ of $k+1$ ***Lagrange polynomial basis function*** defining $w(x)$ over the range of the $g^{th}$ of $m$ overlapping subsets of the data\n",
    "\n",
    "$$\\begin{array}{c|ccc|ll}\n",
    "g & +0 & \\cdots & +k & \\text{basis functions} & \\text{domain} \\\\\\hline\n",
    "0 & x_{(0)} & \\cdots & x_{(k)} & l_{00},\\cdots, l_{0k} & \\left[x_{(0)}, x_{(k)}\\right)\\\\\n",
    "1 & x_{(k)} & \\cdots & x_{(2k)} & l_{10},\\cdots, l_{1k}& \\left[x_{(k)}, x_{(2k)}\\right)\\\\\n",
    "\\vdots\\\\\n",
    "g & x_{(gk)} & \\cdots & x_{(gk+k)}& l_{g0},\\cdots, l_{gk}& \\left[x_{(gk)}, x_{(gk+k)}\\right)\\\\\n",
    "\\vdots &\\\\ \n",
    "m-1 & x_{(n-2k)} & \\cdots & x_{(n-k)} & l_{(n-1)0},\\cdots, l_{(n-1)k}& \\left[x_{(n-2k)}, x_{(n-k)}\\right)\\\\\n",
    "m & x_{(n-k)} & \\cdots & x_{(n)} & l_{(n-1)0},\\cdots, l_{(n-1)k}& \\left[x_{(n-k)}, x_{(k)}\\right]\\\\\n",
    "\\end{array}$$\n",
    "\n",
    "Mapping a function through points, as is done here by the ***Lagrange piecewise polynomial*** is called ***interpolation*** and this is distinct from ***approximation*** in which a reduced representation of a function is used in place of the function. Both of these are again distinct from ***estimation***, in which the parameters within a family of functional forms are chosen so the resulting function resembles observed data points. And finally, these are all again distinct from ***smoothing***, in which the family of functional forms is chosen to be simple and parsimonious and yet still capable of representating the important characteristics of the data, e.g., $E[y|x]$ or $y=\\beta_0+\\beta_1x$.\n",
    "\n",
    "*This problem and conlcuding comments are inspired by **Lagrange polynomials** in the **Models for Interpolation** and **Models for Smoothing Data** sections of Chapter 4.1 **Function Approximation and Smoothing** on pages 154-156 and 157 and the paragraphs in the **introduction** and **Estimation** sections of Chapter **Approximation of Functions** on page 147 and 162 of James E. Gentle's **Computational Statistics** textbook. [Errata Warning: on page 156, cubic Lagrange polynomials join four adjacent points, not three; and, piecewise Lagrangian polynomials are not necessarily smooth at knots.]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e28ddd",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def construct_Lagrange_piecewise_polynomial(x, y, order):\n",
    "    \n",
    "    '''\n",
    "    `x`/`y` : are numpy arrays of the same length\n",
    "    `order` : each piecewise interpolation will use `order+1` data points\n",
    "    \n",
    "              Piecewise functions are end-to-end, so for ``order=2` and len(x)=5`\n",
    "              two piecewise Lagrange polynomials of `order 2` will be made from\n",
    "              `len(x[:3])=3` and `len(x[2:])=3` data points and connect at `x[2]`\n",
    "    '''\n",
    "    \n",
    "    def Lagrange_piecewise_polynomial(w):\n",
    "        pass\n",
    "    \n",
    "    return Lagrange_piecewise_polynomial # which may be evaluated over, e.g., `np.linspace(x[0],x[-1],n)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c404ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for function checking with plotting\n",
    "# add as many such cells you like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ecad38",
   "metadata": {},
   "source": [
    "## Hints\n",
    "\n",
    "- A ***Lagrange polynomial basis function*** is just $\\displaystyle l_j(w) = \\prod_{i \\not = j} \\frac{w-x_{(i)}}{x_{(j)}-x_{(i)}}$ so all the extra stuff up above is just the details for the ***piecewise*** version.\n",
    "\n",
    "- Consider defining the components of `Lagrange_piecewise_polynomial` and then putting them together, e.g.,\n",
    "\n",
    "```\n",
    "def construct_jth_Lagrange_basis_function(j, x_subset): # ignores piecewise stuff\n",
    "  # order will be len(x_subset)-1\n",
    "  def jth_Lagrange_basis_function(w): # works for np.array w\n",
    "    pass\n",
    "  return jth_Lagrange_basis_function\n",
    "  \n",
    "def construct_Lagrange_polynomial(j, x_subset, y_subset): # ignores piecewise stuff\n",
    "  # order will be len(x_subset)-1\n",
    "  def Lagrange_polynomial(w): # works for np.array w\n",
    "    pass\n",
    "  return Lagrange_polynomial  \n",
    "```\n",
    "- Adding `@np.vectorize` just above, e.g., `def jth_Lagrange_basis_function(w)` will allow the function to be written for scalar `w` but called using np.array `w`.\n",
    "\n",
    "- You can confirm the correctness of your function by verifying graphically that the ***Lagrange piecewise polynomial*** correctly travels through `x` and `y`, e.g.,\n",
    "\n",
    "```\n",
    "x,y = sorted(stats.norm.rvs(size=5)), stats.norm.rvs(size=5)\n",
    "plt.plot(x,y,'k.')\n",
    "grid = np.linspace(x[0],x[-1], 100)\n",
    "j=1\n",
    "plt.plot(grid, construct_jth_Lagrange_basis_function(j, x)(grid))\n",
    "plt.plot(grid, construct_Lagrange_polynomial(x,y)(grid))\n",
    "plt.plot(grid, construct_Lagrange_piecewise_polynomial(x, y, order=2)(grid))\n",
    "plt.plot(grid, construct_Lagrange_piecewise_polynomial(x, y, order=1)(grid))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3207afbf",
   "metadata": {},
   "source": [
    "### Problem 1 Questions 1-4 (4 points)\n",
    "\n",
    "The `Lagrange_piecewise_polynomial` will be tested in the manner of the plotting example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2033f684",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1 point\n",
    "p1q1 = lambda j, x: #construct_jth_Lagrange_basis_function(j, x) # or similar\n",
    "# i.e., the jth Lagrange basis function of order len(x_subset)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cfe39e",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1 point\n",
    "p1q2 = lambda x,y: #construct_Lagrange_polynomial(x,y) # or similar\n",
    "# i.e., construct_Lagrange_piecewise_polynomial(x,y, order=len(x)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade9adae",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1 point\n",
    "p1q3 = lambda x,y: #construct_Lagrange_piecewise_polynomial(x,y, order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151571f3",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1 point\n",
    "p1q4 = lambda x,y: #construct_Lagrange_piecewise_polynomial(x,y, order=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb9a0bc",
   "metadata": {},
   "source": [
    "### Problem 1 Questions 5 (1 point)\n",
    "\n",
    "Which of the choices below is true about the following Lagrange piecewise polynomial?\n",
    "\n",
    "```\n",
    "x,y = sorted(stats.norm.rvs(size=5)), stats.norm.rvs(size=5)\n",
    "construct_Lagrange_piecewise_polynomial(x,y, order=2)(grid)\n",
    "```\n",
    "\n",
    "- \"A\": It has sharp discontinuities where the pieces connect\n",
    "- \"B\": It rarely transitions smoothely between concave/convex\n",
    "- \"C\": It is continuous and differentiable everywhere\n",
    "- \"D\": It lends itself to trend fitting and data smoothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db84605a",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1 point\n",
    "p1q5 = \"\"#\"<A|B|C|D>\" # answer \"A\", \"B\", \"C\", or \"D\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74684ec5",
   "metadata": {},
   "source": [
    "# Problem 2 (8 points)\n",
    "\n",
    "The canonical problem showcasing the numerical efficiency of transformations is the ***convolution*** of two functions.\n",
    "\n",
    "A. Write a function `f_ZisXplusY_convolution(f_X,g_Y,zgrid)` which takes two density functions `f_X` and `g_Y` and for each each point $z_j$ in equally spaced `zgrid` (i.e., $z_j =z_0+j\\epsilon$) computes\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\sum_{k=0}^m \\epsilon f_X(z_0+\\epsilon k)g_Y(z_j - (z_0+\\epsilon k)) \\approx {}& \\int_{z_0}^{z_m-z_0+m\\epsilon}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\! f_X(z)g_Y(z_j-z) dz \\\\\n",
    "={}&  (f_X * g_Y)(z_j) = p_{Z=X+Y}(z_j) \\\\ \n",
    "\\end{align*}$$\n",
    "\n",
    "\n",
    "B. Complete the function `f_ZisXplusY_FFT(f_X, g_Y, zgrid)` which calculates\n",
    "\n",
    "$$p_{Z=X+Y}(z) = (f_X * g_Y)(z) = \\mathcal F^{-1}(\\mathcal F(f_X(z)) \\cdot \\mathcal F(g_X( z)))$$\n",
    "\n",
    "using any of the `numpy` or `scipy` implementations \n",
    "- `from scipy.fft import fft, ifft # rfft, irfft`\n",
    "- `from numpy.fft import fft, ifft # rfft, irfft`\n",
    "\n",
    "and extracts the normalized output corresponding to the input based on the provided padding scheme.\n",
    "\n",
    "C. Define the program `python FFT(x,w,verbose=True)` which implements the [radix-2 FFT](https://stackoverflow.com/questions/28009590/understanding-the-radix-2-fft-recursive-algorithm) (and see also [here](https://stackoverflow.com/questions/48572647/recursive-inverse-fft)) and specified print statement\n",
    "\n",
    "  > \\begin{align*} &\\text{FFT}(x,w=e^{2\\pi i/n}, \\text{verbose}) \\{\\\\\n",
    "  & \\quad \\text{if}(\\text{length}(x)=1) \\{\\\\\n",
    "  & \\quad \\quad \\text{return } x_0\\\\\n",
    "  & \\quad \\} \\text{else}\\{\\\\\n",
    "  & \\quad \\quad a, \\; b = (x_1,x_3,\\cdots, x_{n-1}), \\; (x_0,x_2,\\cdots,x_{n-2})\\\\\n",
    "  & \\quad \\quad \\tilde a, \\; \\tilde b = \\text{FFT}(n/2, a, w^2, \\text{verbose}), \\; \\text{FFT}(n/2, b, w^2, \\text{verbose}) \\\\\n",
    "  & \\quad \\quad k=\\text{length}(x)/2\\\\\n",
    "  & \\quad \\quad \\text{for}(j = 0, \\cdots, k-1)\\{\\\\\n",
    "  & \\quad \\quad \\quad \\tilde x_j, \\; \\tilde x_{j+k} = \\tilde b_j \\! + \\! w^j \\tilde a_j, \\; \\tilde b_j \\! - \\! w^j \\tilde  a_j \\\\\n",
    "  & \\quad \\quad \\}\\\\  \n",
    "  & \\quad \\quad \\text{if(verbose)}\\{ \\text{print}(\\tilde x) \\}\\\\  \n",
    "  & \\quad \\}\\\\ \n",
    "  & \\quad \\text{return }  \\tilde x\\\\  \n",
    "\\end{align*}\n",
    "\n",
    "D. Create `f_ZisXplusY_FFT2` which is just `f_ZisXplusY_FFT` except that it uses the radix-2 `FFT` implementation above in place of the built-in `numpy` or `scipy` `fft` functions. \n",
    "\n",
    "*This problem is inspired by the **Convolutions** and **Discrete Transformations** sections in Chapter 3.3 **Efficiency** on pages 124-126 of James E. Gentle's **Computational Statistics** textbook. [Errata Warnings: on page 125-126, $n$ in the expression for $c(y)$ and $b(y)$ is a typo and should be $m$; on page 126 immediately thereafter, rather than introducing the new variable $k$, it would be clearer to continue to use $m$ as the \"midpoint\"; and in the code on page 126 `wp` should be `ws` and the for loop shoud go to `k-1` not `n-1`.]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743bd41b",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from scipy.fft import fft, ifft # rfft, irfft\n",
    "from numpy.fft import fft, ifft # rfft, irfft\n",
    "\n",
    "# A. \n",
    "def f_ZisXplusY_convolution(f_X, g_Y, zgrid):\n",
    "    '''\n",
    "    Riemann integral approximation (over `zgrid`) \n",
    "    of convolution (f_X*g_Y)(z*) for each `z*` in zgrid\n",
    "    '''\n",
    "    \n",
    "    f_ZisXplusY_convolution_grid = 0*zgrid\n",
    "    # <complete>\n",
    "    return f_ZisXplusY_convolution_grid\n",
    "    \n",
    "# B.\n",
    "def f_ZisXplusY_FFT(f_X, g_Y, zgrid):\n",
    "    '''\n",
    "    Discrete convolution theorem approximation of convolution (f_X*g_Y)(z*) \n",
    "    with normalized output corresonding to input with len(output) = len(zgrid)\n",
    "    \n",
    "    Based on [`numpy|`scipy`] `fft` and related implementations.\n",
    "    '''\n",
    "    \n",
    "    f_X_vec = f_X(zgrid)\n",
    "    g_Y_vec = g_Y(zgrid)\n",
    "    f_X_vec = np.array(f_X_vec.tolist() + [0]*(len(zgrid)-1))\n",
    "    g_Y_vec = np.array(g_Y_vec.tolist() + [0]*(len(zgrid)-1))  \n",
    "    \n",
    "    convolution_theorem = lambda f_X_vec, g_Y_vec: f_X_vec*g_Y_vec # replace with correct form    \n",
    "    f_ZisXplusY_FFT_grid = convolution_theorem(g_Y_vec, g_Y_vec)\n",
    "    # <complete convolution_theorem, correct extraction, normalization>    \n",
    "    return np.abs(f_ZisXplusY_FFT_grid)\n",
    "\n",
    "# C.\n",
    "def FFT(x, w):\n",
    "    '''\n",
    "    Radix-2 FFT requires\n",
    "        w = np.exp(2j*np.pi/len(x)) on first function call\n",
    "        len(x)=2**p or len(x)=1 every function call\n",
    "    '''\n",
    "    #<complete\n",
    "    pass\n",
    "    \n",
    "# D.\n",
    "def f_ZisXplusY_FFT2(f_X, g_Y, zgrid):\n",
    "    '''\n",
    "    Discrete convolution theorem approximation of convolution (f_X*g_Y)(z*) \n",
    "    with normalized output corresonding to input with len(output) = len(zgrid)\n",
    "\n",
    "    Based on `FFT` above and not [`numpy|`scipy`] `fft` and related implementations.\n",
    "    '''\n",
    "    #<complete>\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723f3ec8",
   "metadata": {},
   "source": [
    "## Hints\n",
    "\n",
    "- `f_ZisXplusY_convolution(f_X,g_Y,zgrid)` may not be based on integration functions such as in `scipy.integrate`; but, it may be checked, e.g., with \n",
    "\n",
    "```\n",
    "import scipy.integrate as integrate\n",
    "def f_ZisXplusY_integrate_quad(f_X,g_Y,z):    \n",
    "    @np.vectorize\n",
    "    def integrate_quad(z_):\n",
    "        return integrate.quad(lambda t: f_X(t)*g_Y(z_-t), np.min(z), np.max(z))\n",
    "    return integrate_quad(z)\n",
    "```\n",
    "\n",
    "- Review **Section 2.3.2 Convolution Theorem**. Especially the material at the end of the section regarding discrete approximations of the ***convolution theorem***.\n",
    "\n",
    "- `f_ZisXplusY_FFT(f_X,g_Y,zgrid)` cannot simply use `fftconvolve` from `scipy.signal`; but, it may be checked, e.g., with \n",
    "\n",
    "```\n",
    "from scipy.signal import fftconvolve\n",
    "def f_ZisXplusY_fftconvolve(f_X, g_Y, zgrid):    \n",
    "                                 # fftconvolve(..., mode='same') automatically correctly zero-pads \n",
    "    f_ZisXplusY_fftconvolve_grid = fftconvolve(f_X(zgrid),g_Y(zgrid),'same') \n",
    "                                 # output to corresponds to input withouth manual extraction \n",
    "                                 # but normalization is still required\n",
    "    return f_ZisXplusY_fftconvolve_grid/f_ZisXplusY_fftconvolve_grid.sum()/(zgrid[1]-zgrid[0])\n",
    "```\n",
    "\n",
    "- Any of these funtions may be visually compared with, e.g.,\n",
    "\n",
    "```\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "f_X = stats.norm.pdf\n",
    "f_G = f_X\n",
    "epsilon = 12/10**8\n",
    "zgrid = np.arange(-6,6,epsilon)\n",
    "for f in [f_ZisXplusY_convolution, f_ZisXplusY_integrate_quad, \n",
    "          f_ZisXplusY_fftconvolve, f_ZisXplusY_FFT, FFT]:\n",
    "    plt.plot(zgrid, f(f_X, g_Y, zgrid))\n",
    "```\n",
    "\n",
    "- What is `FFT(x, -w)`?  Could it help confirm that `FFT(x, w)` is working?\n",
    "\n",
    "- You can use `import time` to examine run times\n",
    "\n",
    "```\n",
    "toc = time.perf_counter()\n",
    "# do something\n",
    "tic = time.perf_counter()\n",
    "print(tic-toc)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d036052",
   "metadata": {},
   "source": [
    "## Problem 2 Questions 1-5 (5 points)\n",
    "\n",
    "The functions `f_ZisXplusY_convolution`, `f_ZisXplusY_FFT`, `f_ZisXplusY_FFT2` will each be tested in the manner of the plotting example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79908741",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 2 points\n",
    "p2q12 = lambda f_X,g_Y,zgrid: #f_ZisXplusY_convolution(f_X,g_Y,zgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a463c73",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 2 points\n",
    "p2q34 = lambda f_X,g_Y,zgrid: #f_ZisXplusY_FFT(f_X,g_Y,zgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de977cdc",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1 point\n",
    "p2q5 = lambda f_X,g_Y,zgrid: #f_ZisXplusY_FFT2(f_X,g_Y,zgrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92383db3",
   "metadata": {},
   "source": [
    "## Problem 2 Questions 6-7 (2 points)\n",
    "\n",
    "The `FFT` functions will be tested. It should perform the correct ***Fourier transform***, and with different inputs should also be usable as the ***inverse Fourier transform***.  Only `x` inputs satisfying `len(x)=2**p` will be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33ddd48",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 2 points\n",
    "p2q67 = lambda x,w: #FFT(x,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04a5d23",
   "metadata": {},
   "source": [
    "### Problem 2 Question 8a (1/2 point)\n",
    "\n",
    "For problems of the size \n",
    "\n",
    "```\n",
    "epsilon = 12/2**10\n",
    "zgrid = np.arange(0,1,epsilon)\n",
    "```\n",
    "\n",
    "which are the three slowest algorithms in order starting with the slowest?\n",
    "\n",
    "- \"A\": `f_ZisXplusY_FFT` \n",
    "- \"B\": `f_ZisXplusY_FFT2`\n",
    "- \"C\": `f_ZisXplusY_fftconvolve`\n",
    "- \"D\": `f_ZisXplusY_convolution`\n",
    "- \"E\": `f_ZisXplusY_integrate_quad`\n",
    "\n",
    "***You may import the necessary libraries for the purposes of time-benchmarking `f_ZisXplusY_fftconvolve` and `f_ZisXplusY_integrate_quad` (and confirming that outputs of your own implementations are correct) but these libraries may not be used as part of your own implementations.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292da504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# cell to test out algorithm timing\n",
    "# add as many such cells you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bead47",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1/2 point\n",
    "p2q8a = \"\"# \"<A|B|C|D|E><A|B|C|D|E><A|B|C|D|E>\" \n",
    "          # e.g., \"ABC\" means \"A\" is the slowest, \"B\" is the second slowest, and \"C\" is the second slowest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2df2dc",
   "metadata": {},
   "source": [
    "### Problem 2 Question 8b (1/2 point)\n",
    "\n",
    "How much longer does `FFT` take to run compared to (`scipy/numpy`) `fft` for `x = np.arange(2**10)`?\n",
    "- \"A\": 1-2 times as long\n",
    "- \"B\": 2-5 times as long\n",
    "- \"C\": 5-10 times as long\n",
    "- \"D\": 10-20 times as long\n",
    "- \"E\": more that 20 times as long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5206618b",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1/2 point\n",
    "p2q8b = \"\"#<\"A\"|\"B\"|\"C\"|\"D\"|\"E\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecad32d",
   "metadata": {},
   "source": [
    "# Problem 3 (7 points)\n",
    "\n",
    "***Horner's method*** and ***Minimal Newton Form*** define recursive factorizations of \n",
    "\n",
    "$$f_k(x) = \\sum_{j=0}^kw_jx^j$$\n",
    "\n",
    "from which $f_k(x)$ may be evaluated by repeated applications of multiplication by a first order function of $x$ followed addition of a scaler value. \n",
    "\n",
    "By recursively factoring $f_k$ one order of magnitude at a time, these methods make evaluating a polynomial computationally efficient.  E.g., ***Horner's method*** requires $k$ additions and $k$ multiplications, the minimal number required to evaluate a $k^{th}$ order polynomial $f_k(x)$.\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "  \\\\\n",
    "  &  \\large \\text{Horner's Method} && \\large  \\text{Minimal Newton Form (for $x\\in[a,b]$) }\\\\\n",
    "  & \\text{factor out a single $x$ at each step} && \\text{$|\\underset{x\\in[a,b]}{g_j(x)}|>0$ has no roots, but $(|g_j(x)| - \\underset{x\\in[a,b]}{\\min} |g_j(x)|)$ has roots $x_k = \\underset{x\\in[a,b]}{\\text{argmin}} |g_j(x)|$}\\\\\n",
    "  q_k = {} & q_k' + w_0 & g_{j}(x) = {} & \\overbrace{(x-\\xi_j)\\underbrace{g_{j-1}(x)}_{>0, \\; x \\in [a,b]}}^{g_{j}(x)-d_j} + d_j, \\quad d_j  = \\underset{x \\ \\in [a,b]}{\\text{sign}}(g_{j}(x))\\underset{x \\ \\in [a,b]}{\\min} |g_{j}(x)| = g_{j}(\\xi_j) \\\\\n",
    "\\begin{array}{l}=\\\\\\\\=\\end{array} {} & \\begin{array}{l}x (q_{k-1}'+w_1) + w_0 \\\\\\\\ x (x(q_{k-2}'+w_2)+w_1) + w_0\\end{array} &= {} & (x-\\xi_j)\\left(\\overbrace{(x-\\xi_{j-1})\\underbrace{g_{j-2}(x)}_{>0, \\; x \\in [a,b]}}^{g_{j-1}(x)-d_{j-1}} + d_{j-1}\\right) + d_j, \\quad d_{j-1}  = \\underset{x \\ \\in [a,b]}{\\text{sign}}(g_{j-1}(x))\\underset{x \\ \\in [a,b]}{\\min} |g_{j-1}(x)| = g_{j-1}(\\xi_{j-1}) \\\\ \n",
    " \\vdots \\;\\, {} &&  \\vdots  \\;\\,  &\\\\\n",
    "= {} & x (x( \\cdots x(x(w_k) + w_{k-1}) \\cdots +w_2)+w_1) + w_0 & = {} & (x-\\xi_j) ((x-\\xi_{j-1}) ( \\cdots  ((x_1-\\xi_1)(0+d_0) + d_{1}) \\cdots  +d_{j-1}) + d_j \\\\\\\\\n",
    "  \\end{align*}\n",
    "  \n",
    "> I.e., ***minimal Newton form*** first factors the roots of $f_k(x)$ in the interval $[a,b]$ so\n",
    "  $$f_k(x) = g_{k-R}(x)\\prod_{i=1}^R(x-\\xi_i), \\quad |g_{k-R}(x)|>0 \\text{ for } x \\in [a,b]$$\n",
    "  and then (recursively) reformulates $g_{j}(x)$ as $(g_{j}(x)-d_j)+d_j$ so that $(g_{j}(x)-d_j)$ is minimally vertically shifted (to \\*just\\* touch the $y=0$ axis in the interval $[a,b]$) allowing the new root $(x-d_j)$ to be factored from $(g_{j}(x)-d_j)$. \n",
    "\n",
    "Like ***Horner's method*** and ***minimal Newton form***, ***truncated orthogonal basis function representations*** \n",
    "\n",
    "$$f(x) \\approx \\overset{\\text{very inefficient}}{\\underset{\\text{can be avoided}}{\\sum_{k=0}^K c_k q_k(x)}} \\; = \\sum_{k=0}^K w_k x^k$$\n",
    "  \n",
    "can also be efficiently recursively evaluated\n",
    "\n",
    "- without evaluating each orthogonal basis function $q_k$ (which is itself a $k^{th}$ order polynomial that can have $k+1$ non-zero terms)\n",
    "- without knowing the $w_k$ coefficient for each $x^k$ term of the final polynomial approximation (in order to apply ***Horner's method***)\n",
    "\n",
    "using the ***three-term recurrence relation***. Reducing each $q_k(x)$ down to first order polynomials using the ***three-term recurrence relation*** and then rearranging the terms produces the now familiar \"multiplication-addition recursion\" for polynomial function evaluation\n",
    "\n",
    "> \\begin{align*}\n",
    "  {} & \\mathscr{f}_{k+2} =  \\mathscr{f}_{k+1} =  0  \\\\\n",
    "  {} & \\text{for ($j = k, k-1, ..., 1$)} \\{ \\\\\n",
    "  {} & \\quad \\mathscr{f}_{j} =  c_j + (r_{j+1} x + s_{j+1}) \\mathscr{f}_{j+1}  - t_{j+2}\\mathscr{f}_{j+2}  \\\\\n",
    "  {} & \\quad \\text{if(verbose){print$(\\mathscr{f}_{j})$}}\\\\\n",
    "  {} & \\}\\\\ \n",
    "  f(x) \\approx  {} & \\mathscr{f}_{0} = c_0q_0(x)  + q_1(x) \\mathscr{f}_{1} - t_2 \\mathscr{f}_{2}\\\\ {}\\\\\n",
    "  \\end{align*}\n",
    ">\n",
    ">  - where $r_j, s_j$, and $t_j$ are from the ***three-term recurrence relation*** $q_k(x) = (r_k x + s_k)q_{k-1}(x) - t_kq_{k-2}(x)$\n",
    ">    - e.g., for Chebyshev polynomials $r_k=2, s_k=0,$ and $t_k=1$ for $k\\geq 2$\n",
    ">  - $q_0$ and $q_1$ are the $0^{th}$ and $1^{st}$ order orthogonal polynomial basis function\n",
    ">    - e.g., for the ***Chebyshev*** and ***Legendre*** (i.e., ***Jacobi***) and ***Chebyshev-Hermite polynomial bases*** $q_0(x) = 1$ and $q_1(x) = x$\n",
    ">  - and this is the ***Clenshaw algorithm*** which is a result of the so-called [\"reverse\"](https://en.wikipedia.org/wiki/Clenshaw_algorithm#Clenshaw_algorithm) or [\"downward\"](https://mathworld.wolfram.com/ClenshawRecurrenceFormula.html) ***Clenshaw recurrence formula***\n",
    "    - which is usually given in terms of an alternatively indexed parameterization of the three-term recurrence relation\n",
    "      $$q_{k+1}(x) = \\alpha_k(x)q_{k}(x) + \\beta_k(x)q_{k-2}(x)$$\n",
    "\n",
    "\n",
    "Define the function `efficient_othogpolyapproxeval(x, c, q1, q0=1, r_k = lambda k: 2, s_k = lambda k: 0, t_k = lambda k: 1, verbose=False)` which accepts the ***Fourier coefficients*** `c = [c0, c1, c2, ..., ck]` and the ***three-term recurrence formula*** terms for a ***truncated orthogonal polynomial basis*** approximation of a function and then, \n",
    "for the approximation evaluated at `x`, prints the sequence of partial sums (if `verbose=True`) and returns the approximation of the ***Clenshaw algorithm*** above.\n",
    "  \n",
    "*This problem is inspired by Algorithm 4.1 **Evaluation of a Truncated Expansion in Orthogaonal Polynomials at $x$** and the **Computations Involving Polynomials** and **Relations among the Members of an Orthogonal System** sections of Chapter 4.3 **Orthogonal Polynomials** on pages 168-170 of James E. Gentle's **Computational Statistics** textbook. [Errata Warning: however, equation 4.41 (termed the \"Nested Newton Form\") is a unique **Newton Polynomial** whose \"centers\" cannot be changes without corresponding adjustments of the coefficients $\\{c_k\\}$ so the subsequent statement*\n",
    "\n",
    "> *...for careful choices of the \"centers\" $a_i$, it has good numerical stability*\n",
    "\n",
    "*is confused because (despite appearing to) this doesn't actually refer to the \"Nested Newton Form\" but instead refers to the evaluation of a differently parameterized **Newton Polynomial** constructed using the **Minimal Newton Form** introduced above which automatically specifies 'careful choices of the \"centers\"' providing \"good numerical stability\" as detailed in the \"Stable Evaluation of Polynomials\" manuscript by Mesztenyi and Witzgall (1967) ([available here](https://scicomp.stackexchange.com/questions/13023/accurate-polynomial-evaluation-in-floating-point)); and $q$ is a misprint and should be $f$ in Algorithm 4.1 on page 170; and the subscripts for $r, t$, and $s$ are off by one relative to the previous notation given for the \"three-term recursion formula\" in equation 4.39 on page 168; and the `for` loop goes to $0$, but the formulas for $r_k,s_k,$ and $t_k$ only apply for $k \\geq 2$ since they are based on first specifying $q_0(x)$ and $q_1(x)$.]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3869f8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficient_othogpolyapproxeval(x, c, q1, q0=1, r_k = lambda k: 2, \n",
    "                                                  s_k = lambda k: 0, \n",
    "                                                  t_k = lambda k: 1, verbose=False):\n",
    "    '''\n",
    "    Clenshaw algorithm evaluated at x for Fourier coefficients c\n",
    "    with initial two orthogonal polynomial basis functions q0(x) and q1(x)\n",
    "    and three-term recurrence formula functions of k, r_k, s_k, t_k \n",
    "    '''\n",
    "    \n",
    "    # <complete>\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cbc24f",
   "metadata": {},
   "source": [
    "## Hints\n",
    "\n",
    "- You can check your results with the inefficient alternative as, e.g.,\n",
    "\n",
    "```\n",
    "from scipy.special import eval_legendre, eval_chebyt, eval_laguerre, eval_hermitenorm\n",
    "# inefficient since each `eval_legendre` evaluates an order-k polynomial\n",
    "sum([c_k*eval_<func>(k,x) for k,c_k in enumerate(c)])\n",
    "# but see also\n",
    "# e.g., `scipy.special.legendre(c_k)(x)`\n",
    "# e.g., `np.polynomial.chebyshev.Chebyshev(c)(x)`\n",
    "# etc.\n",
    "# https://docs.scipy.org/doc/scipy/reference/special.html#orthogonal-polynomials\n",
    "# https://numpy.org/doc/stable/reference/routines.polynomials.html#documentation-for-the-polynomial-package\n",
    "```\n",
    "\n",
    "- For ***three-term recurrence relation*** terms see **Section 2.4.1 Standard Polynomials**. E.g., for ***Legendre Polynomials***, input `x` for `q1` and specify\n",
    "\n",
    "```\n",
    "r_k = lambda k: (2*k-1)/k\n",
    "s_k = lambda k: 0\n",
    "t_k = lambda k: (k-1)/k\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc086098",
   "metadata": {},
   "source": [
    "## Problem 3 Questions 1-5 (5 points)\n",
    "\n",
    "The `efficient_othogpolyapproxeval` function will be tested for ***Legendre, Chebyshev, Laguerre, and Chebyshev-Hermite polynomials***.\n",
    "\n",
    "For `x, c = 0.5, 5*[1]`, what is the final print statement and final approximation?\n",
    "Return five digits, 1.2345, for both answers.\n",
    "\n",
    "1. `efficient_othogpolyapproxeval(x, c, <fill in the remaining arguments for Legendre polynomials>)`\n",
    "2. `efficient_othogpolyapproxeval(x, c, <fill in the remaining arguments for Chebyshev (first kind) polynomials>)`\n",
    "\n",
    "3&4. `efficient_othogpolyapproxeval(x, c, <fill in the remaining arguments for Laguerre polynomials>)`\n",
    "\n",
    "5. `efficient_othogpolyapproxeval(x, c, <fill in the remaining arguments for Chebyshev-Hermite polynomials>)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7aa37f",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1 point\n",
    "# last partial sum and final output for Legendre polynomial approximation\n",
    "x, c = 0.5, 5*[1]\n",
    "p3q1 = ()#(<final print statement>, <final approximation value>)\n",
    "# return a tuple of two numbers rounded to include 5 digits for each, e.g., 1.2345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b194e5f9",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1 point\n",
    "# last partial sum and final output for Chebyshev (first kind) polynomial approximation\n",
    "p3q2 = ()#(<final print statement>, <final approximation value>)\n",
    "# return a tuple of two numbers rounded to include 5 digits for each, e.g., 1.2345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed70b83",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 2 points\n",
    "# last partial sum and final output for Laguerre polynomial approximation\n",
    "p3q34 = ()#(<final print statement>, <final approximation value>)\n",
    "# return a tuple of two numbers rounded to include 5 digits for each, e.g., 1.2345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e480cf7a",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1 point\n",
    "# last partial sum and final output for Chebyshev-Hermite polynomial approximation\n",
    "p3q5 = ()#(<final print statement>, <final approximation value>) \n",
    "# return a tuple of two numbers rounded to include 5 digits for each, e.g., 1.2345"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084a66e2",
   "metadata": {},
   "source": [
    "### Problem 3 Questions 6-7 (2 points)\n",
    "\n",
    "Compare the computational time requirements of \n",
    "\n",
    "```\n",
    "from scipy.special import eval_legendre, eval_chebyt, eval_laguerre, eval_hermitenorm\n",
    "for eval_f in [eval_legendre, eval_chebyt, eval_laguerre, eval_hermitenorm]:\n",
    "    sum([c_k*eval_f(k,x) for k,c_k in enumerate(c)])\n",
    "```\n",
    "\n",
    "against your own implementation with `efficient_othogpolyapproxeval`.\n",
    "\n",
    "***You may import the necessary libraries for the purposes of time-benchmarking `sum([c_k*eval_f(k,x) for k,c_k in enumerate(c)])` (and confirming that outputs of your own implementations are correct) but these libraries may not be used as part of your own implementations.***\n",
    "\n",
    "6. For `x,c = 0.5,1000*[1]`, which of the following correctly portrays the speed of `efficient_othogpolyapproxeval<>` relative to `sum([c_k*eval_f(k,x) for k,c_k in enumerate(c)])`?\n",
    "\n",
    "- \"A\": 2-3 times slower\n",
    "- \"B\": 2-3 times faster\n",
    "- \"C\": 3-6 times faster\n",
    "- \"D\": 6-10 times faster\n",
    "\n",
    "7. Does this hold for `x,c = 0.5,10000*[1]`? And why?\n",
    "- \"A\": Yes: same complexity class, e.g., O(n)=O(cn)\n",
    "- \"B\": No: 10 times more data 10 times faster\n",
    "- \"C\": Yes: the slight difference is due to slight overhead differences\n",
    "- \"D\": No: different complexity classes, e.g., O(n) versus O(n^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4628e0b1",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1 point\n",
    "p3q6 = \"\"#\"<A|B|C|D>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9a112b",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1 point\n",
    "p3q7 = \"\"#\"<Yes|No>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eb0e20",
   "metadata": {},
   "source": [
    "# Problem 4 (5 points)\n",
    "\n",
    "The magic function `%%time` shortcuts the `tic-toc` template that has been used for timing thus far; however, the alternative `%%timeit` improves upon this template by instead measuring average performance over many runs of the code rather than just a single run.  This allows idiosyncratic run-to-run deviations to be averaged out of  performance benchmarking.\n",
    "\n",
    "For this problem \n",
    "\n",
    "- import the following libraries and set `r`\n",
    "\n",
    "    ```\n",
    "    import numpy as np\n",
    "    import math\n",
    "    from scipy.stats import uniform, norm\n",
    "    import scipy\n",
    "    r = 10000000\n",
    "    ```\n",
    "\n",
    "- run a function in question in separate cells with the `%%timeit` \"magic function\" as the first line of the cell\n",
    "\n",
    "    ```\n",
    "    %%timeit \n",
    "    <call one of the functions>\n",
    "    ```\n",
    "\n",
    "    - **DO NOT include cells with magic functions in your submission**: comment out `%%timeit` in your submission so that the cells you turn in are\n",
    "\n",
    "    ```\n",
    "    # %%timeit\n",
    "    <call one of the functions>\n",
    "    ```\n",
    "\n",
    "- put a cell resetting the random seed in a cell above each \"`%%timeit`\" cell, and run it before running the corresponding \"`%%timeit`\" cell so that every function call is run on the same random data\n",
    "\n",
    "    ```\n",
    "    np.random.seed(42) # for scipy.stats!\n",
    "    ```\n",
    "\n",
    "\n",
    "### Question 1 (1 point)\n",
    "\n",
    "Base python `stdlib` uses `list` data structures while `numpy` uses `array` data structures whose operations can be \"vectorized\"; and, the `math` library generally provides algorithms tailored towards numerical accuracy.\n",
    "\n",
    "Rank the run times (fastest to slowest) of the functions\n",
    "\n",
    "- \"A\": `np.log(uniform.rvs(size=r))`\n",
    "- \"B\": `sum(np.log(uniform.rvs(size=r)))`\n",
    "- \"C\": `(np.log(uniform.rvs(size=r))).sum()`\n",
    "- \"D\": `np.vectorize(math.log)(uniform.rvs(size=r)).sum()`\n",
    "- \"E\": `math.fsum(np.log(uniform.rvs(size=r)))`\n",
    "\n",
    "and indicate which two of them have the closest run times.\n",
    "\n",
    "### Question 2 (1 point)\n",
    "\n",
    "The premier resource in Python for random number generation from specific probability distributions is the [shockingly comprehensive](https://docs.scipy.org/doc/scipy/reference/stats.html) statistical library [scipy.stats](https://scipy.github.io/devdocs/tutorial/stats.html), which by default uses the [NumPy `rng`](https://scipy.github.io/devdocs/tutorial/stats.html#random-number-generation) for pseudorandom number generation.\n",
    "\n",
    "Rank the run times (fastest to slowest) of the functions\n",
    "\n",
    "- \"A\": `norm.rvs(size=r)`\n",
    "- \"B\": `norm.ppf(uniform.rvs(size=r))`\n",
    "- \"C\": `norm.pdf(np.linspace(0,1,r))`\n",
    "- \"D\": `np.e**uniform.rvs(size=r)`\n",
    "- \"E\": `np.exp(uniform.rvs(size=r))`\n",
    "\n",
    "### Question 3 (1 point)\n",
    "\n",
    "As expected, and implied from the results above, different kinds of ***pseudorandom numbers*** require different computational times.  But even within a single class of ***pseudorandom numbers***, some implementations can be faster than others.\n",
    "\n",
    "Rank the run times (fastest to slowest) of the functions\n",
    "\n",
    "- \"A\": `np.random.randint(1, 999, r)/1000`\n",
    "- \"B\": `stats.randint(1, 999).rvs(r)/1000`\n",
    "- \"C\": `np.random.randint(1, 99999, r)/100000`\n",
    "- \"D\": `stats.randint(1, 99999).rvs(r)/100000`\n",
    "- \"E\": `uniform.rvs(size=r)`\n",
    "\n",
    "### Question 4 (1 point)\n",
    "\n",
    "Different implementations generally have different performance characteristics; and, the performance of some algorithms can work well for some inputs and not others.\n",
    "\n",
    "Rank the run times (fastest to slowest) of the functions\n",
    "\n",
    "- \"A\": `np.fft.fft(np.linspace(0,1,2**15))`\n",
    "- \"B\": `np.fft.rfft(np.linspace(0,1,2**15))`\n",
    "- \"C\": `np.fft.rfft(np.linspace(0,1,2**15-1))`\n",
    "- \"D\": `scipy.fft.fft(np.linspace(0,1,2**15))`\n",
    "- \"E\": `scipy.fft.rfft(np.linspace(0,1,2**15))`\n",
    "- \"F\": `scipy.fft.rfft(np.linspace(0,1,2**15-1))`\n",
    "\n",
    "and see if you can understand what is causing the differences in speed.\n",
    "\n",
    "> What do you make of the excerpt \n",
    ">\n",
    "> \"Miscellaneous – NumPy is written in C and it is faster than SciPy is all aspects of execution. It is suitable for computation of data and statistics, and basic mathematical calculation. SciPy is suitable for complex computing of numerical data. There are many who consider NumPy as a part of SciPy as most of the functions of NumPy are present in SciPy directly or indirectly. SciPy’s current application in machine learning has made it more popular than NumPy.\"\n",
    ">\n",
    "> from [this summary](https://www.freelancinggig.com/blog/2018/12/09/what-is-the-difference-between-numpy-and-scipy/) found with a google search of \"numpy vs scipy\"?\n",
    "\n",
    "### Question 5 (1 point)\n",
    "\n",
    "For a finale, consider the following functions (commonly encountered as components of statistical distributions), compared to a couple other (now) familiar computations.\n",
    "\n",
    "Rank the run times (fastest to slowest) of the functions\n",
    "\n",
    "- \"A\": `scipy.special.gamma(r*[1.5])`\n",
    "- \"B\": `scipy.special.beta(r*[1.5],r*[1.5])`\n",
    "- \"C\": `scipy.special.comb(r*[r],r*[int(r/2)])`\n",
    "- \"D\": `np.polynomial.chebyshev.Chebyshev(np.linspace(0,1,r))(0.5)`\n",
    "- \"E\": `np.linalg.solve(np.random.randint(0,2500,(2500,2500)),np.random.randint(0,2500,(2500,1)))`\n",
    "\n",
    "*This problem is inspired by **Evalutation of Special Functions** and **Evaluation of Distribution Functions and Their Inverses** Sections in Chapter 4.1 on pages 158-159 of James E. Gentle's **Computational Statistics** textbook.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42786271",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import uniform, norm\n",
    "import scipy\n",
    "r = 10000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a080442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the seed before each of the cells below\n",
    "np.random.seed(42) # add as many of these cells as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30a734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit # COMMENT OUT `%%timeit` -> `# %%timeit` for submission\n",
    "#<call one of the functions>  # add as many of these cells as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e73225",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1 point\n",
    "p4q1 = (\"\", # <A|B|C|D|E><A|B|C|D|E><A|B|C|D|E><A|B|C|D|E><A|B|C|D|E> \n",
    "        # e.g., \"ABCDE\" means \"A\" is the fasted down to \"E\" which is the slowest\n",
    "        \"\") # <A|B|C|D><A|B|C|D>\n",
    "        # e.g., \"AB\" means \"A\" an \"B\" have the closest run times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98aa4d3",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1 point\n",
    "p4q2 = \"\"# \"<A|B|C|D|E><A|B|C|D|E><A|B|C|D|E><A|B|C|D|E><A|B|C|D|E>\" \n",
    "         # e.g., \"ABCDE\" means \"A\" is the fasted down to \"E\" which is the slowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f29ac3",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1 point\n",
    "p4q3 = \"\"# \"<A|B|C|D|E><A|B|C|D|E><A|B|C|D|E><A|B|C|D|E><A|B|C|D|E>\" \n",
    "         # e.g., \"ABCDE\" means \"A\" is the fasted down to \"E\" which is the slowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9fcda4",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1 point\n",
    "p4q4 = \"\"# \"<A|B|C|D|E|F><A|B|C|D|E|F><A|B|C|D|E|F><A|B|C|D|E|F><A|B|C|D|E|F><A|B|C|D|E|F>\" \n",
    "         # e.g., \"ABCDEF\" means \"A\" is the fasted down to \"F\" which is the slowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ffa5c7",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1 point\n",
    "p4q5 = \"\"# \"<A|B|C|D|E><A|B|C|D|E><A|B|C|D|E><A|B|C|D|E><A|B|C|D|E>\" \n",
    "         # e.g., \"ABCDE\" means \"A\" is the fasted down to \"E\" which is the slowest"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
